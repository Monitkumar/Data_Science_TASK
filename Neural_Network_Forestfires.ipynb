{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e93d4411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "629728ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1bff0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>aug</td>\n",
       "      <td>sat</td>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>nov</td>\n",
       "      <td>tue</td>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0     mar  fri  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1     oct  tue  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2     oct  sat  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3     mar  fri  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4     mar  sun  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0  ...         0   \n",
       "..    ...  ...   ...    ...    ...   ...   ...  ..   ...   ...  ...       ...   \n",
       "512   aug  sun  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0  ...         0   \n",
       "513   aug  sun  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  ...         0   \n",
       "514   aug  sun  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  ...         0   \n",
       "515   aug  sat  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0  ...         0   \n",
       "516   nov  tue  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0  ...         0   \n",
       "\n",
       "     monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0           0         0         0         1         0         0         0   \n",
       "1           0         0         0         0         0         0         1   \n",
       "2           0         0         0         0         0         0         1   \n",
       "3           0         0         0         1         0         0         0   \n",
       "4           0         0         0         1         0         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         1         0   \n",
       "\n",
       "     monthsep  size_category  \n",
       "0           0          small  \n",
       "1           0          small  \n",
       "2           0          small  \n",
       "3           0          small  \n",
       "4           0          small  \n",
       "..        ...            ...  \n",
       "512         0          large  \n",
       "513         0          large  \n",
       "514         0          large  \n",
       "515         0          small  \n",
       "516         0          small  \n",
       "\n",
       "[517 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "data = pd.read_csv('forestfires (1).csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7cdf8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 31)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd0e13a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month             object\n",
       "day               object\n",
       "FFMC             float64\n",
       "DMC              float64\n",
       "DC               float64\n",
       "ISI              float64\n",
       "temp             float64\n",
       "RH                 int64\n",
       "wind             float64\n",
       "rain             float64\n",
       "area             float64\n",
       "dayfri             int64\n",
       "daymon             int64\n",
       "daysat             int64\n",
       "daysun             int64\n",
       "daythu             int64\n",
       "daytue             int64\n",
       "daywed             int64\n",
       "monthapr           int64\n",
       "monthaug           int64\n",
       "monthdec           int64\n",
       "monthfeb           int64\n",
       "monthjan           int64\n",
       "monthjul           int64\n",
       "monthjun           int64\n",
       "monthmar           int64\n",
       "monthmay           int64\n",
       "monthnov           int64\n",
       "monthoct           int64\n",
       "monthsep           int64\n",
       "size_category     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2bd3834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>...</th>\n",
       "      <th>monthdec</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>90.644681</td>\n",
       "      <td>110.872340</td>\n",
       "      <td>547.940039</td>\n",
       "      <td>9.021663</td>\n",
       "      <td>18.889168</td>\n",
       "      <td>44.288201</td>\n",
       "      <td>4.017602</td>\n",
       "      <td>0.021663</td>\n",
       "      <td>12.847292</td>\n",
       "      <td>0.164410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017408</td>\n",
       "      <td>0.038685</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.061896</td>\n",
       "      <td>0.032882</td>\n",
       "      <td>0.104449</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>0.029014</td>\n",
       "      <td>0.332689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.520111</td>\n",
       "      <td>64.046482</td>\n",
       "      <td>248.066192</td>\n",
       "      <td>4.559477</td>\n",
       "      <td>5.806625</td>\n",
       "      <td>16.317469</td>\n",
       "      <td>1.791653</td>\n",
       "      <td>0.295959</td>\n",
       "      <td>63.655818</td>\n",
       "      <td>0.371006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130913</td>\n",
       "      <td>0.193029</td>\n",
       "      <td>0.062137</td>\n",
       "      <td>0.241199</td>\n",
       "      <td>0.178500</td>\n",
       "      <td>0.306138</td>\n",
       "      <td>0.062137</td>\n",
       "      <td>0.043980</td>\n",
       "      <td>0.168007</td>\n",
       "      <td>0.471632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.700000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>90.200000</td>\n",
       "      <td>68.600000</td>\n",
       "      <td>437.700000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>91.600000</td>\n",
       "      <td>108.300000</td>\n",
       "      <td>664.200000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>19.300000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>92.900000</td>\n",
       "      <td>142.400000</td>\n",
       "      <td>713.900000</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.570000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>96.200000</td>\n",
       "      <td>291.300000</td>\n",
       "      <td>860.600000</td>\n",
       "      <td>56.100000</td>\n",
       "      <td>33.300000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>1090.840000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             FFMC         DMC          DC         ISI        temp          RH  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean    90.644681  110.872340  547.940039    9.021663   18.889168   44.288201   \n",
       "std      5.520111   64.046482  248.066192    4.559477    5.806625   16.317469   \n",
       "min     18.700000    1.100000    7.900000    0.000000    2.200000   15.000000   \n",
       "25%     90.200000   68.600000  437.700000    6.500000   15.500000   33.000000   \n",
       "50%     91.600000  108.300000  664.200000    8.400000   19.300000   42.000000   \n",
       "75%     92.900000  142.400000  713.900000   10.800000   22.800000   53.000000   \n",
       "max     96.200000  291.300000  860.600000   56.100000   33.300000  100.000000   \n",
       "\n",
       "             wind        rain         area      dayfri  ...    monthdec  \\\n",
       "count  517.000000  517.000000   517.000000  517.000000  ...  517.000000   \n",
       "mean     4.017602    0.021663    12.847292    0.164410  ...    0.017408   \n",
       "std      1.791653    0.295959    63.655818    0.371006  ...    0.130913   \n",
       "min      0.400000    0.000000     0.000000    0.000000  ...    0.000000   \n",
       "25%      2.700000    0.000000     0.000000    0.000000  ...    0.000000   \n",
       "50%      4.000000    0.000000     0.520000    0.000000  ...    0.000000   \n",
       "75%      4.900000    0.000000     6.570000    0.000000  ...    0.000000   \n",
       "max      9.400000    6.400000  1090.840000    1.000000  ...    1.000000   \n",
       "\n",
       "         monthfeb    monthjan    monthjul    monthjun    monthmar    monthmay  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean     0.038685    0.003868    0.061896    0.032882    0.104449    0.003868   \n",
       "std      0.193029    0.062137    0.241199    0.178500    0.306138    0.062137   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         monthnov    monthoct    monthsep  \n",
       "count  517.000000  517.000000  517.000000  \n",
       "mean     0.001934    0.029014    0.332689  \n",
       "std      0.043980    0.168007    0.471632  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.000000    0.000000  \n",
       "75%      0.000000    0.000000    1.000000  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29bd2f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month            0\n",
       "day              0\n",
       "FFMC             0\n",
       "DMC              0\n",
       "DC               0\n",
       "ISI              0\n",
       "temp             0\n",
       "RH               0\n",
       "wind             0\n",
       "rain             0\n",
       "area             0\n",
       "dayfri           0\n",
       "daymon           0\n",
       "daysat           0\n",
       "daysun           0\n",
       "daythu           0\n",
       "daytue           0\n",
       "daywed           0\n",
       "monthapr         0\n",
       "monthaug         0\n",
       "monthdec         0\n",
       "monthfeb         0\n",
       "monthjan         0\n",
       "monthjul         0\n",
       "monthjun         0\n",
       "monthmar         0\n",
       "monthmay         0\n",
       "monthnov         0\n",
       "monthoct         0\n",
       "monthsep         0\n",
       "size_category    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02a589d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['month','day'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1464849",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "data['size_category'] = le.fit_transform(data['size_category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5977dce5",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a7e4fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('size_category',axis=1)\n",
    "y = data['size_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d65b06e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>...</th>\n",
       "      <th>monthdec</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.44</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.29</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.16</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FFMC    DMC     DC   ISI  temp  RH  wind  rain   area  dayfri  ...  \\\n",
       "0    86.2   26.2   94.3   5.1   8.2  51   6.7   0.0   0.00       1  ...   \n",
       "1    90.6   35.4  669.1   6.7  18.0  33   0.9   0.0   0.00       0  ...   \n",
       "2    90.6   43.7  686.9   6.7  14.6  33   1.3   0.0   0.00       0  ...   \n",
       "3    91.7   33.3   77.5   9.0   8.3  97   4.0   0.2   0.00       1  ...   \n",
       "4    89.3   51.3  102.2   9.6  11.4  99   1.8   0.0   0.00       0  ...   \n",
       "..    ...    ...    ...   ...   ...  ..   ...   ...    ...     ...  ...   \n",
       "512  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0   6.44       0  ...   \n",
       "513  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  54.29       0  ...   \n",
       "514  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  11.16       0  ...   \n",
       "515  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0   0.00       0  ...   \n",
       "516  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0   0.00       0  ...   \n",
       "\n",
       "     monthdec  monthfeb  monthjan  monthjul  monthjun  monthmar  monthmay  \\\n",
       "0           0         0         0         0         0         1         0   \n",
       "1           0         0         0         0         0         0         0   \n",
       "2           0         0         0         0         0         0         0   \n",
       "3           0         0         0         0         0         1         0   \n",
       "4           0         0         0         0         0         1         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         0         0   \n",
       "\n",
       "     monthnov  monthoct  monthsep  \n",
       "0           0         0         0  \n",
       "1           0         1         0  \n",
       "2           0         1         0  \n",
       "3           0         0         0  \n",
       "4           0         0         0  \n",
       "..        ...       ...       ...  \n",
       "512         0         0         0  \n",
       "513         0         0         0  \n",
       "514         0         0         0  \n",
       "515         0         0         0  \n",
       "516         1         0         0  \n",
       "\n",
       "[517 rows x 28 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6804b1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "512    0\n",
       "513    0\n",
       "514    0\n",
       "515    1\n",
       "516    1\n",
       "Name: size_category, Length: 517, dtype: int32"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97ce1db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.05959472e-01, -1.32332557e+00, -1.83047676e+00, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [-8.10203395e-03, -1.17954077e+00,  4.88890915e-01, ...,\n",
       "        -4.40225453e-02,  5.78503817e+00, -7.06081245e-01],\n",
       "       [-8.10203395e-03, -1.04982188e+00,  5.60715454e-01, ...,\n",
       "        -4.40225453e-02,  5.78503817e+00, -7.06081245e-01],\n",
       "       ...,\n",
       "       [-1.64008316e+00, -8.46647711e-01,  4.74768113e-01, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [ 6.80956663e-01,  5.49002541e-01,  2.69382214e-01, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [-2.02087875e+00, -1.68591332e+00, -1.78044169e+00, ...,\n",
       "         2.27156334e+01, -1.72859706e-01, -7.06081245e-01]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(X)\n",
    "x_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04f57e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(x_scaled,y,test_size=0.20,random_state=15,stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e95b840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.66282354, -0.4027903 ,  0.58250492, ..., -0.04402255,\n",
       "        -0.17285971,  1.41626761],\n",
       "       [ 0.49962543,  0.53962527,  0.69992594, ..., -0.04402255,\n",
       "        -0.17285971,  1.41626761],\n",
       "       [ 0.15509608,  1.98997626,  0.73704873, ..., -0.04402255,\n",
       "        -0.17285971, -0.70608125],\n",
       "       ...,\n",
       "       [-1.07795633, -1.31551118, -0.78821394, ..., -0.04402255,\n",
       "        -0.17285971, -0.70608125],\n",
       "       [ 0.33642731,  0.15984586,  0.51027687, ..., -0.04402255,\n",
       "        -0.17285971,  1.41626761],\n",
       "       [ 0.26389482, -0.18555022,  0.7963645 , ..., -0.04402255,\n",
       "        -0.17285971,  1.41626761]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "261cfabe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.31829419,  0.10983376,  0.48445232, ..., -0.04402255,\n",
       "        -0.17285971,  1.41626761],\n",
       "       [ 0.26389482,  0.6521525 ,  0.44490847, ..., -0.04402255,\n",
       "        -0.17285971, -0.70608125],\n",
       "       [ 0.08256358, -0.35434107,  0.74148733, ..., -0.04402255,\n",
       "        -0.17285971,  1.41626761],\n",
       "       ...,\n",
       "       [ 0.1732292 ,  2.14938984,  0.83066274, ..., -0.04402255,\n",
       "        -0.17285971, -0.70608125],\n",
       "       [ 0.06443046,  0.87564409,  0.82582063, ..., -0.04402255,\n",
       "        -0.17285971, -0.70608125],\n",
       "       [ 0.19136233, -0.97480373,  0.59783825, ..., -0.04402255,\n",
       "         5.78503817, -0.70608125]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fb37e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208    0\n",
       "270    1\n",
       "401    1\n",
       "26     1\n",
       "313    1\n",
       "      ..\n",
       "201    0\n",
       "343    1\n",
       "425    1\n",
       "507    1\n",
       "226    0\n",
       "Name: size_category, Length: 104, dtype: int32"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60ce4c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(28,input_dim=28,activation='relu'))\n",
    "model.add(Dense(24,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "594ffa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3ad5b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "28/28 [==============================] - 1s 15ms/step - loss: 0.6535 - accuracy: 0.6304 - val_loss: 0.6418 - val_accuracy: 0.7226\n",
      "Epoch 2/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.6018 - accuracy: 0.7246 - val_loss: 0.6237 - val_accuracy: 0.7445\n",
      "Epoch 3/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5715 - accuracy: 0.7246 - val_loss: 0.6125 - val_accuracy: 0.7445\n",
      "Epoch 4/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.5502 - accuracy: 0.7283 - val_loss: 0.6064 - val_accuracy: 0.7445\n",
      "Epoch 5/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.5290 - accuracy: 0.7355 - val_loss: 0.6013 - val_accuracy: 0.7810\n",
      "Epoch 6/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7500 - val_loss: 0.6014 - val_accuracy: 0.7883\n",
      "Epoch 7/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4912 - accuracy: 0.7536 - val_loss: 0.6003 - val_accuracy: 0.7956\n",
      "Epoch 8/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.7681 - val_loss: 0.6033 - val_accuracy: 0.7956\n",
      "Epoch 9/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7862 - val_loss: 0.6081 - val_accuracy: 0.7956\n",
      "Epoch 10/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7899 - val_loss: 0.6141 - val_accuracy: 0.7956\n",
      "Epoch 11/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.8043 - val_loss: 0.6203 - val_accuracy: 0.7956\n",
      "Epoch 12/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4083 - accuracy: 0.8116 - val_loss: 0.6216 - val_accuracy: 0.7956\n",
      "Epoch 13/150\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3938 - accuracy: 0.82 - 0s 3ms/step - loss: 0.3917 - accuracy: 0.8261 - val_loss: 0.6259 - val_accuracy: 0.7883\n",
      "Epoch 14/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3782 - accuracy: 0.8297 - val_loss: 0.6413 - val_accuracy: 0.7883\n",
      "Epoch 15/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3614 - accuracy: 0.8514 - val_loss: 0.6415 - val_accuracy: 0.7883\n",
      "Epoch 16/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3474 - accuracy: 0.8478 - val_loss: 0.6502 - val_accuracy: 0.7883\n",
      "Epoch 17/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3338 - accuracy: 0.8659 - val_loss: 0.6566 - val_accuracy: 0.7883\n",
      "Epoch 18/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3179 - accuracy: 0.8696 - val_loss: 0.6712 - val_accuracy: 0.7956\n",
      "Epoch 19/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3046 - accuracy: 0.8804 - val_loss: 0.6719 - val_accuracy: 0.7956\n",
      "Epoch 20/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2983 - accuracy: 0.8877 - val_loss: 0.6883 - val_accuracy: 0.7956\n",
      "Epoch 21/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2794 - accuracy: 0.8804 - val_loss: 0.6900 - val_accuracy: 0.8029\n",
      "Epoch 22/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2672 - accuracy: 0.8949 - val_loss: 0.7109 - val_accuracy: 0.8029\n",
      "Epoch 23/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2506 - accuracy: 0.9058 - val_loss: 0.7166 - val_accuracy: 0.8029\n",
      "Epoch 24/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2384 - accuracy: 0.9094 - val_loss: 0.7214 - val_accuracy: 0.8175\n",
      "Epoch 25/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2231 - accuracy: 0.9094 - val_loss: 0.7300 - val_accuracy: 0.8248\n",
      "Epoch 26/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2112 - accuracy: 0.9312 - val_loss: 0.7466 - val_accuracy: 0.8175\n",
      "Epoch 27/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2001 - accuracy: 0.9094 - val_loss: 0.7580 - val_accuracy: 0.8321\n",
      "Epoch 28/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1866 - accuracy: 0.9384 - val_loss: 0.7733 - val_accuracy: 0.8321\n",
      "Epoch 29/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1741 - accuracy: 0.9420 - val_loss: 0.7791 - val_accuracy: 0.8394\n",
      "Epoch 30/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1632 - accuracy: 0.9529 - val_loss: 0.7981 - val_accuracy: 0.8467\n",
      "Epoch 31/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1523 - accuracy: 0.9601 - val_loss: 0.8165 - val_accuracy: 0.8321\n",
      "Epoch 32/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1440 - accuracy: 0.9601 - val_loss: 0.8229 - val_accuracy: 0.8321\n",
      "Epoch 33/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1352 - accuracy: 0.9601 - val_loss: 0.8405 - val_accuracy: 0.8321\n",
      "Epoch 34/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1246 - accuracy: 0.9674 - val_loss: 0.8436 - val_accuracy: 0.8394\n",
      "Epoch 35/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1196 - accuracy: 0.9638 - val_loss: 0.8721 - val_accuracy: 0.8394\n",
      "Epoch 36/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1117 - accuracy: 0.9710 - val_loss: 0.8739 - val_accuracy: 0.8467\n",
      "Epoch 37/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1053 - accuracy: 0.9746 - val_loss: 0.9020 - val_accuracy: 0.8321\n",
      "Epoch 38/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0976 - accuracy: 0.9819 - val_loss: 0.9094 - val_accuracy: 0.8540\n",
      "Epoch 39/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0949 - accuracy: 0.9783 - val_loss: 0.9146 - val_accuracy: 0.8540\n",
      "Epoch 40/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0882 - accuracy: 0.9819 - val_loss: 0.9344 - val_accuracy: 0.8613\n",
      "Epoch 41/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0824 - accuracy: 0.9783 - val_loss: 0.9473 - val_accuracy: 0.8540\n",
      "Epoch 42/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0788 - accuracy: 0.9819 - val_loss: 0.9621 - val_accuracy: 0.8540\n",
      "Epoch 43/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0727 - accuracy: 0.9819 - val_loss: 0.9746 - val_accuracy: 0.8467\n",
      "Epoch 44/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0709 - accuracy: 0.9819 - val_loss: 0.9978 - val_accuracy: 0.8613\n",
      "Epoch 45/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0722 - accuracy: 0.9819 - val_loss: 1.0046 - val_accuracy: 0.8540\n",
      "Epoch 46/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0629 - accuracy: 0.9855 - val_loss: 1.0054 - val_accuracy: 0.8540\n",
      "Epoch 47/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0597 - accuracy: 0.9891 - val_loss: 1.0257 - val_accuracy: 0.8613\n",
      "Epoch 48/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 1.0000 - val_loss: 1.0350 - val_accuracy: 0.8613\n",
      "Epoch 49/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9891 - val_loss: 1.0535 - val_accuracy: 0.8613\n",
      "Epoch 50/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0509 - accuracy: 0.9964 - val_loss: 1.0702 - val_accuracy: 0.8540\n",
      "Epoch 51/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 1.0000 - val_loss: 1.0761 - val_accuracy: 0.8540\n",
      "Epoch 52/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0447 - accuracy: 0.9964 - val_loss: 1.0861 - val_accuracy: 0.8467\n",
      "Epoch 53/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0433 - accuracy: 1.0000 - val_loss: 1.1011 - val_accuracy: 0.8613\n",
      "Epoch 54/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0412 - accuracy: 1.0000 - val_loss: 1.1128 - val_accuracy: 0.8540\n",
      "Epoch 55/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0398 - accuracy: 0.9964 - val_loss: 1.1219 - val_accuracy: 0.8540\n",
      "Epoch 56/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 1.1422 - val_accuracy: 0.8540\n",
      "Epoch 57/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 1.1586 - val_accuracy: 0.8467\n",
      "Epoch 58/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 1.1675 - val_accuracy: 0.8467\n",
      "Epoch 59/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 1.1801 - val_accuracy: 0.8540\n",
      "Epoch 60/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 1.1839 - val_accuracy: 0.8540\n",
      "Epoch 61/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 1.2034 - val_accuracy: 0.8540\n",
      "Epoch 62/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0269 - accuracy: 1.0000 - val_loss: 1.2205 - val_accuracy: 0.8613\n",
      "Epoch 63/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 1.2289 - val_accuracy: 0.8540\n",
      "Epoch 64/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 1.2517 - val_accuracy: 0.8613\n",
      "Epoch 65/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 1.2478 - val_accuracy: 0.8540\n",
      "Epoch 66/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 1.2581 - val_accuracy: 0.8540\n",
      "Epoch 67/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 1.2716 - val_accuracy: 0.8540\n",
      "Epoch 68/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 1.2891 - val_accuracy: 0.8540\n",
      "Epoch 69/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 1.2932 - val_accuracy: 0.8540\n",
      "Epoch 70/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 1.3055 - val_accuracy: 0.8540\n",
      "Epoch 71/150\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 1.3041 - val_accuracy: 0.8540\n",
      "Epoch 72/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 1.3244 - val_accuracy: 0.8540\n",
      "Epoch 73/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 1.3331 - val_accuracy: 0.8540\n",
      "Epoch 74/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 1.3434 - val_accuracy: 0.8686\n",
      "Epoch 75/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 1.3457 - val_accuracy: 0.8613\n",
      "Epoch 76/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 1.3592 - val_accuracy: 0.8540\n",
      "Epoch 77/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 1.3699 - val_accuracy: 0.8540\n",
      "Epoch 78/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 1.3778 - val_accuracy: 0.8613\n",
      "Epoch 79/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 1.3868 - val_accuracy: 0.8613\n",
      "Epoch 80/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.3990 - val_accuracy: 0.8613\n",
      "Epoch 81/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 1.4062 - val_accuracy: 0.8613\n",
      "Epoch 82/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.4163 - val_accuracy: 0.8613\n",
      "Epoch 83/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.4240 - val_accuracy: 0.8613\n",
      "Epoch 84/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.4303 - val_accuracy: 0.8613\n",
      "Epoch 85/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.4350 - val_accuracy: 0.8686\n",
      "Epoch 86/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.4515 - val_accuracy: 0.8613\n",
      "Epoch 87/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.4633 - val_accuracy: 0.8686\n",
      "Epoch 88/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.4592 - val_accuracy: 0.8613\n",
      "Epoch 89/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.4774 - val_accuracy: 0.8686\n",
      "Epoch 90/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.4840 - val_accuracy: 0.8759\n",
      "Epoch 91/150\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.4903 - val_accuracy: 0.8759\n",
      "Epoch 92/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.5016 - val_accuracy: 0.8759\n",
      "Epoch 93/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.5098 - val_accuracy: 0.8759\n",
      "Epoch 94/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.5173 - val_accuracy: 0.8686\n",
      "Epoch 95/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.5270 - val_accuracy: 0.8759\n",
      "Epoch 96/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.5362 - val_accuracy: 0.8759\n",
      "Epoch 97/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.5422 - val_accuracy: 0.8759\n",
      "Epoch 98/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.5499 - val_accuracy: 0.8759\n",
      "Epoch 99/150\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.5591 - val_accuracy: 0.8759\n",
      "Epoch 100/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.5666 - val_accuracy: 0.8759\n",
      "Epoch 101/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.5760 - val_accuracy: 0.8759\n",
      "Epoch 102/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.5774 - val_accuracy: 0.8759\n",
      "Epoch 103/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.5879 - val_accuracy: 0.8759\n",
      "Epoch 104/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.5952 - val_accuracy: 0.8759\n",
      "Epoch 105/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.6056 - val_accuracy: 0.8759\n",
      "Epoch 106/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.6164 - val_accuracy: 0.8832\n",
      "Epoch 107/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.6220 - val_accuracy: 0.8759\n",
      "Epoch 108/150\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 1.00 - 0s 3ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.6225 - val_accuracy: 0.8759\n",
      "Epoch 109/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.6398 - val_accuracy: 0.8832\n",
      "Epoch 110/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.6409 - val_accuracy: 0.8759\n",
      "Epoch 111/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.6471 - val_accuracy: 0.8832\n",
      "Epoch 112/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.6586 - val_accuracy: 0.8832\n",
      "Epoch 113/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.6646 - val_accuracy: 0.8759\n",
      "Epoch 114/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.6742 - val_accuracy: 0.8759\n",
      "Epoch 115/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.6815 - val_accuracy: 0.8832\n",
      "Epoch 116/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.6845 - val_accuracy: 0.8832\n",
      "Epoch 117/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.6981 - val_accuracy: 0.8832\n",
      "Epoch 118/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.6994 - val_accuracy: 0.8832\n",
      "Epoch 119/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.7092 - val_accuracy: 0.8832\n",
      "Epoch 120/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.7149 - val_accuracy: 0.8759\n",
      "Epoch 121/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.7258 - val_accuracy: 0.8832\n",
      "Epoch 122/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.7304 - val_accuracy: 0.8832\n",
      "Epoch 123/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.7377 - val_accuracy: 0.8832\n",
      "Epoch 124/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.7428 - val_accuracy: 0.8832\n",
      "Epoch 125/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.7510 - val_accuracy: 0.8832\n",
      "Epoch 126/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.7568 - val_accuracy: 0.8832\n",
      "Epoch 127/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.7638 - val_accuracy: 0.8832\n",
      "Epoch 128/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.7664 - val_accuracy: 0.8832\n",
      "Epoch 129/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.7744 - val_accuracy: 0.8832\n",
      "Epoch 130/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.7812 - val_accuracy: 0.8832\n",
      "Epoch 131/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.7878 - val_accuracy: 0.8832\n",
      "Epoch 132/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.7934 - val_accuracy: 0.8832\n",
      "Epoch 133/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.8017 - val_accuracy: 0.8832\n",
      "Epoch 134/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.8080 - val_accuracy: 0.8832\n",
      "Epoch 135/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.8145 - val_accuracy: 0.8832\n",
      "Epoch 136/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.8215 - val_accuracy: 0.8832\n",
      "Epoch 137/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.8253 - val_accuracy: 0.8832\n",
      "Epoch 138/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.8353 - val_accuracy: 0.8832\n",
      "Epoch 139/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.8431 - val_accuracy: 0.8832\n",
      "Epoch 140/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.8439 - val_accuracy: 0.8832\n",
      "Epoch 141/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.8531 - val_accuracy: 0.8905\n",
      "Epoch 142/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.8544 - val_accuracy: 0.8832\n",
      "Epoch 143/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.8631 - val_accuracy: 0.8832\n",
      "Epoch 144/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.8659 - val_accuracy: 0.8905\n",
      "Epoch 145/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.8747 - val_accuracy: 0.8905\n",
      "Epoch 146/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.8778 - val_accuracy: 0.8905\n",
      "Epoch 147/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.8874 - val_accuracy: 0.8905\n",
      "Epoch 148/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.8944 - val_accuracy: 0.8905\n",
      "Epoch 149/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.8989 - val_accuracy: 0.8905\n",
      "Epoch 150/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.9044 - val_accuracy: 0.8905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17754f78f70>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,validation_split=0.33,epochs=150,batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed068ffb",
   "metadata": {},
   "source": [
    "## Model testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6efcab87",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model.predict(X_train)\n",
    "rounded = [round(x[0]) for x in y_pred_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32e88f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train1 = pd.DataFrame(rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44a2be94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>413 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "..  ..\n",
       "408  0\n",
       "409  1\n",
       "410  0\n",
       "411  1\n",
       "412  1\n",
       "\n",
       "[413 rows x 1 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f080a874",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model.predict(X_test)\n",
    "rounded1    = [round(x[0]) for x in y_pred_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "411a53ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "..  ..\n",
       "99   0\n",
       "100  1\n",
       "101  1\n",
       "102  1\n",
       "103  0\n",
       "\n",
       "[104 rows x 1 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test1 = pd.DataFrame(rounded1)\n",
    "y_pred_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d50601b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.010360568761825562, 1.0]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy_Train = model.evaluate(X_train,y_pred_train1,verbose=0)\n",
    "Accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e2de195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.022686515003442764, 1.0]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy_Test = model.evaluate(X_test,y_pred_test1,verbose=0)\n",
    "Accuracy_Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe0016d",
   "metadata": {},
   "source": [
    "## Visualizing Accuracy and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8bf9bccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "7/7 [==============================] - 1s 17ms/step - loss: 0.0357 - accuracy: 0.9855 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 2/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 3/150\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 4/150\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 5/150\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 6/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 1.0000\n",
      "Epoch 7/150\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
      "Epoch 8/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 8.3222e-04 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
      "Epoch 9/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 6.8660e-04 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
      "Epoch 10/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 6.2631e-04 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 11/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 6.1297e-04 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 12/150\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 5.7835e-04 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
      "Epoch 13/150\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 5.6341e-04 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
      "Epoch 14/150\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 5.5415e-04 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
      "Epoch 15/150\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 5.3704e-04 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
      "Epoch 16/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 5.2702e-04 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
      "Epoch 17/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 5.1473e-04 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
      "Epoch 18/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 5.0414e-04 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
      "Epoch 19/150\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 4.9115e-04 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
      "Epoch 20/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 4.8219e-04 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
      "Epoch 21/150\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 4.7181e-04 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
      "Epoch 22/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 4.6423e-04 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
      "Epoch 23/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 4.4967e-04 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
      "Epoch 24/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 4.4047e-04 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
      "Epoch 25/150\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 4.3428e-04 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
      "Epoch 26/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 4.2547e-04 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
      "Epoch 27/150\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 4.2649e-04 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
      "Epoch 28/150\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 4.1567e-04 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
      "Epoch 29/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 4.0085e-04 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
      "Epoch 30/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 3.9709e-04 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
      "Epoch 31/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 3.8594e-04 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
      "Epoch 32/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 3.7715e-04 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
      "Epoch 33/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 3.7461e-04 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
      "Epoch 34/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 3.6655e-04 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
      "Epoch 35/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 3.6563e-04 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
      "Epoch 36/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 3.5228e-04 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
      "Epoch 37/150\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 3.4885e-04 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
      "Epoch 38/150\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 3.4391e-04 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
      "Epoch 39/150\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 3.3835e-04 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
      "Epoch 40/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 3.3388e-04 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
      "Epoch 41/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 3.2664e-04 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
      "Epoch 42/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 3.2336e-04 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
      "Epoch 43/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 3.2039e-04 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
      "Epoch 44/150\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 3.1441e-04 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
      "Epoch 45/150\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 3.1111e-04 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 46/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 3.0598e-04 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
      "Epoch 47/150\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 3.0297e-04 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
      "Epoch 48/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.9673e-04 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
      "Epoch 49/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.9319e-04 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
      "Epoch 50/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.8774e-04 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
      "Epoch 51/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.8469e-04 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
      "Epoch 52/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.8454e-04 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
      "Epoch 53/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.7929e-04 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
      "Epoch 54/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.7937e-04 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
      "Epoch 55/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.7232e-04 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
      "Epoch 56/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.6728e-04 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
      "Epoch 57/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.6422e-04 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.6142e-04 - accuracy: 1.0000 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
      "Epoch 59/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.5858e-04 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
      "Epoch 60/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2.5728e-04 - accuracy: 1.0000 - val_loss: 0.0179 - val_accuracy: 1.0000\n",
      "Epoch 61/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.5427e-04 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 1.0000\n",
      "Epoch 62/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.4824e-04 - accuracy: 1.0000 - val_loss: 0.0179 - val_accuracy: 1.0000\n",
      "Epoch 63/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2.4695e-04 - accuracy: 1.0000 - val_loss: 0.0182 - val_accuracy: 1.0000\n",
      "Epoch 64/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.4470e-04 - accuracy: 1.0000 - val_loss: 0.0185 - val_accuracy: 1.0000\n",
      "Epoch 65/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.4117e-04 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 1.0000\n",
      "Epoch 66/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.3826e-04 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 1.0000\n",
      "Epoch 67/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.3875e-04 - accuracy: 1.0000 - val_loss: 0.0185 - val_accuracy: 1.0000\n",
      "Epoch 68/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2.3487e-04 - accuracy: 1.0000 - val_loss: 0.0190 - val_accuracy: 1.0000\n",
      "Epoch 69/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2.3113e-04 - accuracy: 1.0000 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
      "Epoch 70/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.2844e-04 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 1.0000\n",
      "Epoch 71/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.2830e-04 - accuracy: 1.0000 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
      "Epoch 72/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.2325e-04 - accuracy: 1.0000 - val_loss: 0.0196 - val_accuracy: 1.0000\n",
      "Epoch 73/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2.2121e-04 - accuracy: 1.0000 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
      "Epoch 74/150\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.1855e-04 - accuracy: 1.0000 - val_loss: 0.0202 - val_accuracy: 1.0000\n",
      "Epoch 75/150\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2.1721e-04 - accuracy: 1.0000 - val_loss: 0.0203 - val_accuracy: 1.0000\n",
      "Epoch 76/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.1514e-04 - accuracy: 1.0000 - val_loss: 0.0203 - val_accuracy: 1.0000\n",
      "Epoch 77/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2.1266e-04 - accuracy: 1.0000 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
      "Epoch 78/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.1070e-04 - accuracy: 1.0000 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
      "Epoch 79/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.1007e-04 - accuracy: 1.0000 - val_loss: 0.0207 - val_accuracy: 1.0000\n",
      "Epoch 80/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.0697e-04 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 1.0000\n",
      "Epoch 81/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.0503e-04 - accuracy: 1.0000 - val_loss: 0.0211 - val_accuracy: 1.0000\n",
      "Epoch 82/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2.0352e-04 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 1.0000\n",
      "Epoch 83/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.0101e-04 - accuracy: 1.0000 - val_loss: 0.0218 - val_accuracy: 1.0000\n",
      "Epoch 84/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.0019e-04 - accuracy: 1.0000 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
      "Epoch 85/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.9704e-04 - accuracy: 1.0000 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
      "Epoch 86/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.9673e-04 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
      "Epoch 87/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.9407e-04 - accuracy: 1.0000 - val_loss: 0.0222 - val_accuracy: 1.0000\n",
      "Epoch 88/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.9228e-04 - accuracy: 1.0000 - val_loss: 0.0223 - val_accuracy: 1.0000\n",
      "Epoch 89/150\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.9190e-04 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 1.0000\n",
      "Epoch 90/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.8869e-04 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 1.0000\n",
      "Epoch 91/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.8781e-04 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 1.0000\n",
      "Epoch 92/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.8735e-04 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 1.0000\n",
      "Epoch 93/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.8355e-04 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 1.0000\n",
      "Epoch 94/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.8178e-04 - accuracy: 1.0000 - val_loss: 0.0235 - val_accuracy: 1.0000\n",
      "Epoch 95/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.8094e-04 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 0.9714\n",
      "Epoch 96/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.7959e-04 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 1.0000\n",
      "Epoch 97/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.7753e-04 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 1.0000\n",
      "Epoch 98/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.7552e-04 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 0.9714\n",
      "Epoch 99/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.7407e-04 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 0.9714\n",
      "Epoch 100/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.7251e-04 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9714\n",
      "Epoch 101/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.7161e-04 - accuracy: 1.0000 - val_loss: 0.0250 - val_accuracy: 0.9714\n",
      "Epoch 102/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.6983e-04 - accuracy: 1.0000 - val_loss: 0.0251 - val_accuracy: 0.9714\n",
      "Epoch 103/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.6879e-04 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 0.9714\n",
      "Epoch 104/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.6730e-04 - accuracy: 1.0000 - val_loss: 0.0252 - val_accuracy: 0.9714\n",
      "Epoch 105/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.6571e-04 - accuracy: 1.0000 - val_loss: 0.0255 - val_accuracy: 0.9714\n",
      "Epoch 106/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.6495e-04 - accuracy: 1.0000 - val_loss: 0.0255 - val_accuracy: 0.9714\n",
      "Epoch 107/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.6251e-04 - accuracy: 1.0000 - val_loss: 0.0257 - val_accuracy: 0.9714\n",
      "Epoch 108/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.6169e-04 - accuracy: 1.0000 - val_loss: 0.0260 - val_accuracy: 0.9714\n",
      "Epoch 109/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.6047e-04 - accuracy: 1.0000 - val_loss: 0.0262 - val_accuracy: 0.9714\n",
      "Epoch 110/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.5934e-04 - accuracy: 1.0000 - val_loss: 0.0263 - val_accuracy: 0.9714\n",
      "Epoch 111/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 1.3889e-04 - accuracy: 1.00 - 0s 9ms/step - loss: 1.5782e-04 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 0.9714\n",
      "Epoch 112/150\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1.5684e-04 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 0.9714\n",
      "Epoch 113/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.5619e-04 - accuracy: 1.0000 - val_loss: 0.0268 - val_accuracy: 0.9714\n",
      "Epoch 114/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 10ms/step - loss: 1.5498e-04 - accuracy: 1.0000 - val_loss: 0.0271 - val_accuracy: 0.9714\n",
      "Epoch 115/150\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1.5295e-04 - accuracy: 1.0000 - val_loss: 0.0271 - val_accuracy: 0.9714\n",
      "Epoch 116/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.5215e-04 - accuracy: 1.0000 - val_loss: 0.0273 - val_accuracy: 0.9714\n",
      "Epoch 117/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.5107e-04 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 0.9714\n",
      "Epoch 118/150\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1.5050e-04 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 0.9714\n",
      "Epoch 119/150\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1.4893e-04 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 0.9714\n",
      "Epoch 120/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.4747e-04 - accuracy: 1.0000 - val_loss: 0.0279 - val_accuracy: 0.9714\n",
      "Epoch 121/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.4731e-04 - accuracy: 1.0000 - val_loss: 0.0284 - val_accuracy: 0.9714\n",
      "Epoch 122/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.4545e-04 - accuracy: 1.0000 - val_loss: 0.0284 - val_accuracy: 0.9714\n",
      "Epoch 123/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.4439e-04 - accuracy: 1.0000 - val_loss: 0.0286 - val_accuracy: 0.9714\n",
      "Epoch 124/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.4521e-04 - accuracy: 1.0000 - val_loss: 0.0282 - val_accuracy: 0.9714\n",
      "Epoch 125/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.4281e-04 - accuracy: 1.0000 - val_loss: 0.0287 - val_accuracy: 0.9714\n",
      "Epoch 126/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.4113e-04 - accuracy: 1.0000 - val_loss: 0.0287 - val_accuracy: 0.9714\n",
      "Epoch 127/150\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1.4023e-04 - accuracy: 1.0000 - val_loss: 0.0289 - val_accuracy: 0.9714\n",
      "Epoch 128/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.3947e-04 - accuracy: 1.0000 - val_loss: 0.0294 - val_accuracy: 0.9714\n",
      "Epoch 129/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.3854e-04 - accuracy: 1.0000 - val_loss: 0.0293 - val_accuracy: 0.9714\n",
      "Epoch 130/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.3675e-04 - accuracy: 1.0000 - val_loss: 0.0296 - val_accuracy: 0.9714\n",
      "Epoch 131/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.3643e-04 - accuracy: 1.0000 - val_loss: 0.0297 - val_accuracy: 0.9714\n",
      "Epoch 132/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.3575e-04 - accuracy: 1.0000 - val_loss: 0.0303 - val_accuracy: 0.9714\n",
      "Epoch 133/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.3488e-04 - accuracy: 1.0000 - val_loss: 0.0302 - val_accuracy: 0.9714\n",
      "Epoch 134/150\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1.3329e-04 - accuracy: 1.0000 - val_loss: 0.0304 - val_accuracy: 0.9714\n",
      "Epoch 135/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.3229e-04 - accuracy: 1.0000 - val_loss: 0.0308 - val_accuracy: 0.9714\n",
      "Epoch 136/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.3117e-04 - accuracy: 1.0000 - val_loss: 0.0309 - val_accuracy: 0.9714\n",
      "Epoch 137/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.3035e-04 - accuracy: 1.0000 - val_loss: 0.0311 - val_accuracy: 0.9714\n",
      "Epoch 138/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.2942e-04 - accuracy: 1.0000 - val_loss: 0.0312 - val_accuracy: 0.9714\n",
      "Epoch 139/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.2852e-04 - accuracy: 1.0000 - val_loss: 0.0313 - val_accuracy: 0.9714\n",
      "Epoch 140/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.2758e-04 - accuracy: 1.0000 - val_loss: 0.0316 - val_accuracy: 0.9714\n",
      "Epoch 141/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.2679e-04 - accuracy: 1.0000 - val_loss: 0.0316 - val_accuracy: 0.9714\n",
      "Epoch 142/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.2567e-04 - accuracy: 1.0000 - val_loss: 0.0319 - val_accuracy: 0.9714\n",
      "Epoch 143/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.2532e-04 - accuracy: 1.0000 - val_loss: 0.0319 - val_accuracy: 0.9714\n",
      "Epoch 144/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.2447e-04 - accuracy: 1.0000 - val_loss: 0.0322 - val_accuracy: 0.9714\n",
      "Epoch 145/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.2307e-04 - accuracy: 1.0000 - val_loss: 0.0322 - val_accuracy: 0.9714\n",
      "Epoch 146/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.2254e-04 - accuracy: 1.0000 - val_loss: 0.0323 - val_accuracy: 0.9714\n",
      "Epoch 147/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.2165e-04 - accuracy: 1.0000 - val_loss: 0.0326 - val_accuracy: 0.9714\n",
      "Epoch 148/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.2184e-04 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 0.9714\n",
      "Epoch 149/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.1981e-04 - accuracy: 1.0000 - val_loss: 0.0328 - val_accuracy: 0.9714\n",
      "Epoch 150/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.2023e-04 - accuracy: 1.0000 - val_loss: 0.0334 - val_accuracy: 0.9714\n"
     ]
    }
   ],
   "source": [
    "History = model.fit(X_test,y_pred_test1,validation_split=0.33,epochs=150,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "489f0b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1cdc7030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(History.history['accuracy'])\n",
    "plt.plot(History.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc20813c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(History.history['loss'])\n",
    "plt.plot(History.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc799ea",
   "metadata": {},
   "source": [
    "## Tuning of Hyperparameters : Batch Size and epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "41edf440",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15eb060f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optimizers\n",
      "  Downloading Optimizers-v2.1.tar.gz (1.6 kB)\n",
      "Requirement already satisfied: requests>=2.24.0 in c:\\users\\monit\\anaconda3\\lib\\site-packages (from optimizers) (2.25.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\monit\\anaconda3\\lib\\site-packages (from requests>=2.24.0->optimizers) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\monit\\anaconda3\\lib\\site-packages (from requests>=2.24.0->optimizers) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\monit\\anaconda3\\lib\\site-packages (from requests>=2.24.0->optimizers) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\monit\\anaconda3\\lib\\site-packages (from requests>=2.24.0->optimizers) (4.0.0)\n",
      "Building wheels for collected packages: optimizers\n",
      "  Building wheel for optimizers (setup.py): started\n",
      "  Building wheel for optimizers (setup.py): finished with status 'done'\n",
      "  Created wheel for optimizers: filename=Optimizers-2.1-py3-none-any.whl size=2285 sha256=6224537e05845c419c31bbb3789875350a03939b58b82b8c8b9d37139251362c\n",
      "  Stored in directory: c:\\users\\monit\\appdata\\local\\pip\\cache\\wheels\\1d\\e3\\e3\\f0a9b8fd8a9271274d03d4c15e4fed24a70b1d1b0f571bec66\n",
      "Successfully built optimizers\n",
      "Installing collected packages: optimizers\n",
      "Successfully installed optimizers-2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "59d7ec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "def create_model():\n",
    "    model1 = Sequential()\n",
    "    model1.add(Dense(30, input_dim=28, activation='relu'))\n",
    "    model1.add(Dense(28, activation='relu'))\n",
    "    model1.add(Dense(1,activation='sigmoid'))\n",
    "    \n",
    "   \n",
    "    model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b2b514a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "\n",
    "model2 = KerasClassifier(build_fn = create_model,verbose = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f328f8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid search parameters\n",
    "\n",
    "batch_size = [10,20,40]\n",
    "epochs = [10,50,100]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70d13bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grid = dict(batch_size = batch_size,epochs = epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bf49b500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 1/5; 1/9] END ..................batch_size=10, epochs=10; total time=   1.6s\n",
      "[CV 2/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 2/5; 1/9] END ..................batch_size=10, epochs=10; total time=   1.5s\n",
      "[CV 3/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 3/5; 1/9] END ..................batch_size=10, epochs=10; total time=   1.5s\n",
      "[CV 4/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 4/5; 1/9] END ..................batch_size=10, epochs=10; total time=   1.6s\n",
      "[CV 5/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 5/5; 1/9] END ..................batch_size=10, epochs=10; total time=   1.4s\n",
      "[CV 1/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 1/5; 2/9] END ..................batch_size=10, epochs=50; total time=   4.6s\n",
      "[CV 2/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 2/5; 2/9] END ..................batch_size=10, epochs=50; total time=   3.7s\n",
      "[CV 3/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 3/5; 2/9] END ..................batch_size=10, epochs=50; total time=   3.6s\n",
      "[CV 4/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 4/5; 2/9] END ..................batch_size=10, epochs=50; total time=   3.6s\n",
      "[CV 5/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 5/5; 2/9] END ..................batch_size=10, epochs=50; total time=   4.0s\n",
      "[CV 1/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 1/5; 3/9] END .................batch_size=10, epochs=100; total time=   6.4s\n",
      "[CV 2/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 2/5; 3/9] END .................batch_size=10, epochs=100; total time=   6.3s\n",
      "[CV 3/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 3/5; 3/9] END .................batch_size=10, epochs=100; total time=   6.8s\n",
      "[CV 4/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 4/5; 3/9] END .................batch_size=10, epochs=100; total time=   6.7s\n",
      "[CV 5/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 5/5; 3/9] END .................batch_size=10, epochs=100; total time=   7.2s\n",
      "[CV 1/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 1/5; 4/9] END ..................batch_size=20, epochs=10; total time=   1.3s\n",
      "[CV 2/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 2/5; 4/9] END ..................batch_size=20, epochs=10; total time=   1.1s\n",
      "[CV 3/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 3/5; 4/9] END ..................batch_size=20, epochs=10; total time=   1.1s\n",
      "[CV 4/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 4/5; 4/9] END ..................batch_size=20, epochs=10; total time=   1.1s\n",
      "[CV 5/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 5/5; 4/9] END ..................batch_size=20, epochs=10; total time=   1.2s\n",
      "[CV 1/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 1/5; 5/9] END ..................batch_size=20, epochs=50; total time=   2.3s\n",
      "[CV 2/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 2/5; 5/9] END ..................batch_size=20, epochs=50; total time=   2.4s\n",
      "[CV 3/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 3/5; 5/9] END ..................batch_size=20, epochs=50; total time=   2.6s\n",
      "[CV 4/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 4/5; 5/9] END ..................batch_size=20, epochs=50; total time=   2.2s\n",
      "[CV 5/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 5/5; 5/9] END ..................batch_size=20, epochs=50; total time=   2.2s\n",
      "[CV 1/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 1/5; 6/9] END .................batch_size=20, epochs=100; total time=   3.8s\n",
      "[CV 2/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 2/5; 6/9] END .................batch_size=20, epochs=100; total time=   3.8s\n",
      "[CV 3/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 3/5; 6/9] END .................batch_size=20, epochs=100; total time=   4.0s\n",
      "[CV 4/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 4/5; 6/9] END .................batch_size=20, epochs=100; total time=   3.6s\n",
      "[CV 5/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 5/5; 6/9] END .................batch_size=20, epochs=100; total time=   4.1s\n",
      "[CV 1/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 1/5; 7/9] END ..................batch_size=40, epochs=10; total time=   0.9s\n",
      "[CV 2/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 2/5; 7/9] END ..................batch_size=40, epochs=10; total time=   0.9s\n",
      "[CV 3/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 3/5; 7/9] END ..................batch_size=40, epochs=10; total time=   0.9s\n",
      "[CV 4/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x000001775E9C99D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV 4/5; 7/9] END ..................batch_size=40, epochs=10; total time=   0.9s\n",
      "[CV 5/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001775D897B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV 5/5; 7/9] END ..................batch_size=40, epochs=10; total time=   0.9s\n",
      "[CV 1/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 1/5; 8/9] END ..................batch_size=40, epochs=50; total time=   2.4s\n",
      "[CV 2/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 2/5; 8/9] END ..................batch_size=40, epochs=50; total time=   1.6s\n",
      "[CV 3/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 3/5; 8/9] END ..................batch_size=40, epochs=50; total time=   1.6s\n",
      "[CV 4/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 4/5; 8/9] END ..................batch_size=40, epochs=50; total time=   1.6s\n",
      "[CV 5/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 5/5; 8/9] END ..................batch_size=40, epochs=50; total time=   1.6s\n",
      "[CV 1/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 1/5; 9/9] END .................batch_size=40, epochs=100; total time=   2.4s\n",
      "[CV 2/5; 9/9] START batch_size=40, epochs=100...................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 9/9] END .................batch_size=40, epochs=100; total time=   2.4s\n",
      "[CV 3/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 3/5; 9/9] END .................batch_size=40, epochs=100; total time=   2.6s\n",
      "[CV 4/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 4/5; 9/9] END .................batch_size=40, epochs=100; total time=   2.9s\n",
      "[CV 5/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 5/5; 9/9] END .................batch_size=40, epochs=100; total time=   2.4s\n"
     ]
    }
   ],
   "source": [
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model2,param_grid = param_grid,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(x_scaled,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8f11c350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.8780619978904725, using {'batch_size': 10, 'epochs': 100}\n",
      "0.7481516003608704,0.1138919142449346 with: {'batch_size': 10, 'epochs': 10}\n",
      "0.860567593574524,0.058740325537249324 with: {'batch_size': 10, 'epochs': 50}\n",
      "0.8780619978904725,0.05445464004045931 with: {'batch_size': 10, 'epochs': 100}\n",
      "0.7248879909515381,0.13058610598489112 with: {'batch_size': 20, 'epochs': 10}\n",
      "0.8354929089546204,0.06200882943655235 with: {'batch_size': 20, 'epochs': 50}\n",
      "0.8780059695243836,0.052924564608835954 with: {'batch_size': 20, 'epochs': 100}\n",
      "0.7325242638587952,0.15606928938188888 with: {'batch_size': 40, 'epochs': 10}\n",
      "0.7754480957984924,0.06262387268438156 with: {'batch_size': 40, 'epochs': 50}\n",
      "0.8451082944869995,0.06947473939297738 with: {'batch_size': 40, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e99279",
   "metadata": {},
   "source": [
    "## Best result ,when batch-size = 10 and epochs=100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1371f043",
   "metadata": {},
   "source": [
    "## Tuning of Hyperparameter :Number of neurons in activation layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "24a75047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model\n",
    "\n",
    "def create_model1(neuron1,neuron2):\n",
    "    model3 = Sequential()\n",
    "    model3.add(Dense(neuron1,input_dim = 28,activation = 'relu'))\n",
    "    model3.add(Dense(neuron2,activation = 'relu'))\n",
    "    model3.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    model3.compile(loss = 'binary_crossentropy',optimizer = 'adam',metrics = ['accuracy'])\n",
    "    return model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c7a31cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "\n",
    "model4 = KerasClassifier(build_fn = create_model1,verbose = 0,batch_size = 40,epochs = 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cdf8fb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid search parameters\n",
    "\n",
    "neuron1 = [24,28,35]\n",
    "neuron2 = [20,24,28]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b239f33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids = dict(neuron1 = neuron1,neuron2 = neuron2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eb8aa0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START neuron1=24, neuron2=20......................................\n",
      "[CV 1/5; 1/9] END ....................neuron1=24, neuron2=20; total time=   1.0s\n",
      "[CV 2/5; 1/9] START neuron1=24, neuron2=20......................................\n",
      "[CV 2/5; 1/9] END ....................neuron1=24, neuron2=20; total time=   1.0s\n",
      "[CV 3/5; 1/9] START neuron1=24, neuron2=20......................................\n",
      "[CV 3/5; 1/9] END ....................neuron1=24, neuron2=20; total time=   0.9s\n",
      "[CV 4/5; 1/9] START neuron1=24, neuron2=20......................................\n",
      "[CV 4/5; 1/9] END ....................neuron1=24, neuron2=20; total time=   0.9s\n",
      "[CV 5/5; 1/9] START neuron1=24, neuron2=20......................................\n",
      "[CV 5/5; 1/9] END ....................neuron1=24, neuron2=20; total time=   0.9s\n",
      "[CV 1/5; 2/9] START neuron1=24, neuron2=24......................................\n",
      "[CV 1/5; 2/9] END ....................neuron1=24, neuron2=24; total time=   0.9s\n",
      "[CV 2/5; 2/9] START neuron1=24, neuron2=24......................................\n",
      "[CV 2/5; 2/9] END ....................neuron1=24, neuron2=24; total time=   1.1s\n",
      "[CV 3/5; 2/9] START neuron1=24, neuron2=24......................................\n",
      "[CV 3/5; 2/9] END ....................neuron1=24, neuron2=24; total time=   1.1s\n",
      "[CV 4/5; 2/9] START neuron1=24, neuron2=24......................................\n",
      "[CV 4/5; 2/9] END ....................neuron1=24, neuron2=24; total time=   1.0s\n",
      "[CV 5/5; 2/9] START neuron1=24, neuron2=24......................................\n",
      "[CV 5/5; 2/9] END ....................neuron1=24, neuron2=24; total time=   1.4s\n",
      "[CV 1/5; 3/9] START neuron1=24, neuron2=28......................................\n",
      "[CV 1/5; 3/9] END ....................neuron1=24, neuron2=28; total time=   1.2s\n",
      "[CV 2/5; 3/9] START neuron1=24, neuron2=28......................................\n",
      "[CV 2/5; 3/9] END ....................neuron1=24, neuron2=28; total time=   1.1s\n",
      "[CV 3/5; 3/9] START neuron1=24, neuron2=28......................................\n",
      "[CV 3/5; 3/9] END ....................neuron1=24, neuron2=28; total time=   0.9s\n",
      "[CV 4/5; 3/9] START neuron1=24, neuron2=28......................................\n",
      "[CV 4/5; 3/9] END ....................neuron1=24, neuron2=28; total time=   0.9s\n",
      "[CV 5/5; 3/9] START neuron1=24, neuron2=28......................................\n",
      "[CV 5/5; 3/9] END ....................neuron1=24, neuron2=28; total time=   0.9s\n",
      "[CV 1/5; 4/9] START neuron1=28, neuron2=20......................................\n",
      "[CV 1/5; 4/9] END ....................neuron1=28, neuron2=20; total time=   0.9s\n",
      "[CV 2/5; 4/9] START neuron1=28, neuron2=20......................................\n",
      "[CV 2/5; 4/9] END ....................neuron1=28, neuron2=20; total time=   0.9s\n",
      "[CV 3/5; 4/9] START neuron1=28, neuron2=20......................................\n",
      "[CV 3/5; 4/9] END ....................neuron1=28, neuron2=20; total time=   1.0s\n",
      "[CV 4/5; 4/9] START neuron1=28, neuron2=20......................................\n",
      "[CV 4/5; 4/9] END ....................neuron1=28, neuron2=20; total time=   1.0s\n",
      "[CV 5/5; 4/9] START neuron1=28, neuron2=20......................................\n",
      "[CV 5/5; 4/9] END ....................neuron1=28, neuron2=20; total time=   1.2s\n",
      "[CV 1/5; 5/9] START neuron1=28, neuron2=24......................................\n",
      "[CV 1/5; 5/9] END ....................neuron1=28, neuron2=24; total time=   0.9s\n",
      "[CV 2/5; 5/9] START neuron1=28, neuron2=24......................................\n",
      "[CV 2/5; 5/9] END ....................neuron1=28, neuron2=24; total time=   0.9s\n",
      "[CV 3/5; 5/9] START neuron1=28, neuron2=24......................................\n",
      "[CV 3/5; 5/9] END ....................neuron1=28, neuron2=24; total time=   0.9s\n",
      "[CV 4/5; 5/9] START neuron1=28, neuron2=24......................................\n",
      "[CV 4/5; 5/9] END ....................neuron1=28, neuron2=24; total time=   0.9s\n",
      "[CV 5/5; 5/9] START neuron1=28, neuron2=24......................................\n",
      "[CV 5/5; 5/9] END ....................neuron1=28, neuron2=24; total time=   1.0s\n",
      "[CV 1/5; 6/9] START neuron1=28, neuron2=28......................................\n",
      "[CV 1/5; 6/9] END ....................neuron1=28, neuron2=28; total time=   1.2s\n",
      "[CV 2/5; 6/9] START neuron1=28, neuron2=28......................................\n",
      "[CV 2/5; 6/9] END ....................neuron1=28, neuron2=28; total time=   1.1s\n",
      "[CV 3/5; 6/9] START neuron1=28, neuron2=28......................................\n",
      "[CV 3/5; 6/9] END ....................neuron1=28, neuron2=28; total time=   1.1s\n",
      "[CV 4/5; 6/9] START neuron1=28, neuron2=28......................................\n",
      "[CV 4/5; 6/9] END ....................neuron1=28, neuron2=28; total time=   0.9s\n",
      "[CV 5/5; 6/9] START neuron1=28, neuron2=28......................................\n",
      "[CV 5/5; 6/9] END ....................neuron1=28, neuron2=28; total time=   1.2s\n",
      "[CV 1/5; 7/9] START neuron1=35, neuron2=20......................................\n",
      "[CV 1/5; 7/9] END ....................neuron1=35, neuron2=20; total time=   0.9s\n",
      "[CV 2/5; 7/9] START neuron1=35, neuron2=20......................................\n",
      "[CV 2/5; 7/9] END ....................neuron1=35, neuron2=20; total time=   0.9s\n",
      "[CV 3/5; 7/9] START neuron1=35, neuron2=20......................................\n",
      "[CV 3/5; 7/9] END ....................neuron1=35, neuron2=20; total time=   1.0s\n",
      "[CV 4/5; 7/9] START neuron1=35, neuron2=20......................................\n",
      "[CV 4/5; 7/9] END ....................neuron1=35, neuron2=20; total time=   0.9s\n",
      "[CV 5/5; 7/9] START neuron1=35, neuron2=20......................................\n",
      "[CV 5/5; 7/9] END ....................neuron1=35, neuron2=20; total time=   0.9s\n",
      "[CV 1/5; 8/9] START neuron1=35, neuron2=24......................................\n",
      "[CV 1/5; 8/9] END ....................neuron1=35, neuron2=24; total time=   0.9s\n",
      "[CV 2/5; 8/9] START neuron1=35, neuron2=24......................................\n",
      "[CV 2/5; 8/9] END ....................neuron1=35, neuron2=24; total time=   0.9s\n",
      "[CV 3/5; 8/9] START neuron1=35, neuron2=24......................................\n",
      "[CV 3/5; 8/9] END ....................neuron1=35, neuron2=24; total time=   0.9s\n",
      "[CV 4/5; 8/9] START neuron1=35, neuron2=24......................................\n",
      "[CV 4/5; 8/9] END ....................neuron1=35, neuron2=24; total time=   0.9s\n",
      "[CV 5/5; 8/9] START neuron1=35, neuron2=24......................................\n",
      "[CV 5/5; 8/9] END ....................neuron1=35, neuron2=24; total time=   1.3s\n",
      "[CV 1/5; 9/9] START neuron1=35, neuron2=28......................................\n",
      "[CV 1/5; 9/9] END ....................neuron1=35, neuron2=28; total time=   1.1s\n",
      "[CV 2/5; 9/9] START neuron1=35, neuron2=28......................................\n",
      "[CV 2/5; 9/9] END ....................neuron1=35, neuron2=28; total time=   0.9s\n",
      "[CV 3/5; 9/9] START neuron1=35, neuron2=28......................................\n",
      "[CV 3/5; 9/9] END ....................neuron1=35, neuron2=28; total time=   0.9s\n",
      "[CV 4/5; 9/9] START neuron1=35, neuron2=28......................................\n",
      "[CV 4/5; 9/9] END ....................neuron1=35, neuron2=28; total time=   0.9s\n",
      "[CV 5/5; 9/9] START neuron1=35, neuron2=28......................................\n",
      "[CV 5/5; 9/9] END ....................neuron1=35, neuron2=28; total time=   0.9s\n"
     ]
    }
   ],
   "source": [
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid2        = GridSearchCV(estimator = model4,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result2 = grid2.fit(x_scaled,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c17469c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.7325989484786988, using {'neuron1': 35, 'neuron2': 20}\n",
      "0.7209671378135681,0.1378870136506599 with: {'neuron1': 24, 'neuron2': 20}\n",
      "0.7248319625854492,0.14383644916528962 with: {'neuron1': 24, 'neuron2': 24}\n",
      "0.7228902101516723,0.14636961424053557 with: {'neuron1': 24, 'neuron2': 28}\n",
      "0.7228902101516723,0.14598271174689065 with: {'neuron1': 28, 'neuron2': 20}\n",
      "0.7114077568054199,0.11363371617532012 with: {'neuron1': 28, 'neuron2': 24}\n",
      "0.7190627336502076,0.1368140496545262 with: {'neuron1': 28, 'neuron2': 28}\n",
      "0.7325989484786988,0.13784100117748913 with: {'neuron1': 35, 'neuron2': 20}\n",
      "0.7171396613121033,0.12789828505426384 with: {'neuron1': 35, 'neuron2': 24}\n",
      "0.7268483877182007,0.11626632806248637 with: {'neuron1': 35, 'neuron2': 28}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result2.best_score_,grid_result2.best_params_))\n",
    "means = grid_result2.cv_results_['mean_test_score']\n",
    "stds = grid_result2.cv_results_['std_test_score']\n",
    "params = grid_result2.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca7a380",
   "metadata": {},
   "source": [
    "##  Best result at 1st layer 28 Neuron and 2nd layer 24 neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3782d1f8",
   "metadata": {},
   "source": [
    "## Tuning Hyperparameter : Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b5b7e35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model\n",
    "\n",
    "def create_model2(activation_function):\n",
    "    model4 = Sequential()\n",
    "    model4.add(Dense(28,input_dim = 28,activation = activation_function))\n",
    "    model4.add(Dense(24,activation = activation_function))\n",
    "    model4.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    model4.compile(loss = 'binary_crossentropy',optimizer = 'adam',metrics = ['accuracy'])\n",
    "    return model4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7d8d5a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "\n",
    "model5 = KerasClassifier(build_fn = create_model2,verbose = 0,batch_size = 40,epochs = 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f2686d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid search parameters\n",
    "activation_function = ['softmax','relu','tanh']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e087682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids = dict(activation_function=activation_function)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b08d906b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5; 1/3] START activation_function=softmax.................................\n",
      "[CV 1/5; 1/3] END ...............activation_function=softmax; total time=   1.3s\n",
      "[CV 2/5; 1/3] START activation_function=softmax.................................\n",
      "[CV 2/5; 1/3] END ...............activation_function=softmax; total time=   1.1s\n",
      "[CV 3/5; 1/3] START activation_function=softmax.................................\n",
      "[CV 3/5; 1/3] END ...............activation_function=softmax; total time=   1.1s\n",
      "[CV 4/5; 1/3] START activation_function=softmax.................................\n",
      "[CV 4/5; 1/3] END ...............activation_function=softmax; total time=   1.3s\n",
      "[CV 5/5; 1/3] START activation_function=softmax.................................\n",
      "[CV 5/5; 1/3] END ...............activation_function=softmax; total time=   1.0s\n",
      "[CV 1/5; 2/3] START activation_function=relu....................................\n",
      "[CV 1/5; 2/3] END ..................activation_function=relu; total time=   1.0s\n",
      "[CV 2/5; 2/3] START activation_function=relu....................................\n",
      "[CV 2/5; 2/3] END ..................activation_function=relu; total time=   1.0s\n",
      "[CV 3/5; 2/3] START activation_function=relu....................................\n",
      "[CV 3/5; 2/3] END ..................activation_function=relu; total time=   0.9s\n",
      "[CV 4/5; 2/3] START activation_function=relu....................................\n",
      "[CV 4/5; 2/3] END ..................activation_function=relu; total time=   1.0s\n",
      "[CV 5/5; 2/3] START activation_function=relu....................................\n",
      "[CV 5/5; 2/3] END ..................activation_function=relu; total time=   1.0s\n",
      "[CV 1/5; 3/3] START activation_function=tanh....................................\n",
      "[CV 1/5; 3/3] END ..................activation_function=tanh; total time=   1.0s\n",
      "[CV 2/5; 3/3] START activation_function=tanh....................................\n",
      "[CV 2/5; 3/3] END ..................activation_function=tanh; total time=   1.0s\n",
      "[CV 3/5; 3/3] START activation_function=tanh....................................\n",
      "[CV 3/5; 3/3] END ..................activation_function=tanh; total time=   1.1s\n",
      "[CV 4/5; 3/3] START activation_function=tanh....................................\n",
      "[CV 4/5; 3/3] END ..................activation_function=tanh; total time=   1.4s\n",
      "[CV 5/5; 3/3] START activation_function=tanh....................................\n",
      "[CV 5/5; 3/3] END ..................activation_function=tanh; total time=   1.1s\n"
     ]
    }
   ],
   "source": [
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid3        = GridSearchCV(estimator = model5,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result3 = grid3.fit(x_scaled,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7cc22276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.7500560045242309, using {'activation_function': 'tanh'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax'}\n",
      "0.728659451007843,0.1510055827692834 with: {'activation_function': 'relu'}\n",
      "0.7500560045242309,0.1169943840974993 with: {'activation_function': 'tanh'}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result3.best_score_,grid_result3.best_params_))\n",
    "means = grid_result3.cv_results_['mean_test_score']\n",
    "stds = grid_result3.cv_results_['std_test_score']\n",
    "params = grid_result3.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15573212",
   "metadata": {},
   "source": [
    "##  Best result when Activation function is 'tanh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3a0b90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
